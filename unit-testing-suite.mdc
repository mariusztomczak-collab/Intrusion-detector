---
description:
globs:
alwaysApply: false
---
# Unit Testing Suite - Intrusion Detector

## ğŸ“‹ Overview

This document describes the comprehensive unit testing suite for the Intrusion Detector application, implemented in the `tests/unit/` directory. The tests cover key application components and ensure high code quality.

## ğŸ—ï¸ Test Architecture

### Directory Structure
```
tests/
â”œâ”€â”€ conftest.py                   # Pytest configuration and shared fixtures
â”œâ”€â”€ pytest.ini                   # Pytest configuration file
â”œâ”€â”€ unit/                        # Unit tests
â”‚   â”œâ”€â”€ test_api.py             # FastAPI application tests
â”‚   â”œâ”€â”€ test_auth.py            # Authentication logic tests
â”‚   â”œâ”€â”€ test_database.py        # Database operations tests
â”‚   â”œâ”€â”€ test_preprocessor.py    # ML preprocessor tests
â”‚   â””â”€â”€ test_ui_components.py   # Gradio UI component tests
â””â”€â”€ README.md                    # Test documentation
```

### Test Configuration
- **Framework**: pytest 8.3.5
- **Code Coverage**: pytest-cov 6.2.1
- **Mocking**: pytest-mock 3.14.0
- **Async support**: pytest-asyncio 1.1.0
- **Configuration**: pytest.ini

## ğŸ§ª Tested Components

### 1. API Tests (`test_api.py`)

#### Class: `TestAPIEndpoints`
**Purpose**: Testing FastAPI application endpoints

**Tested Functionalities**:
- âœ… Health check endpoint (`/health`)
- âœ… Root endpoint (`/`)
- âœ… Authentication endpoints (`/auth/register`, `/auth/login`)
- âœ… Decision endpoints (`/decisions/single`, `/decisions/`)
- âœ… Error handling for various scenarios

**Key Tests**:
```python
def test_health_check(self):
    """Test health check endpoint"""
    
def test_root_endpoint(self):
    """Test root endpoint"""
    
def test_get_decisions_history_unauthorized(self):
    """Test unauthorized access to decisions"""
    
def test_analyze_traffic_success(self):
    """Test successful traffic analysis"""
```

**Coverage**: 34% of API layer code

### 2. Authentication Tests (`test_auth.py`)

#### Class: `TestUnifiedApp`
**Purpose**: Testing authentication logic in user interface

**Tested Functionalities**:
- âœ… Email format validation
- âœ… Login with valid credentials
- âœ… Handling invalid login credentials
- âœ… Handling empty input data
- âœ… Network error handling

**Key Tests**:
```python
def test_validate_email_valid(self):
    """Test validation of valid email addresses"""
    
def test_handle_login_success(self):
    """Test successful login with mocked API response"""
    
def test_handle_login_invalid_credentials(self):
    """Test handling of invalid login credentials"""
    
def test_handle_login_empty_inputs(self):
    """Test handling of empty input data"""
```

**Coverage**: 38% of UI components code

#### Class: `TestAuthAPI`
**Purpose**: Testing API authentication functions

**Tested Functionalities**:
- âœ… Standalone email validation
- âœ… API error handling

### 3. Database Tests (`test_database.py`)

#### Class: `TestSupabaseClient`
**Purpose**: Testing Supabase client operations

**Tested Functionalities**:
- âœ… Supabase client initialization
- âœ… Database operations (insert, select)
- âœ… Error handling for database operations
- âœ… User decision management

**Key Tests**:
```python
def test_get_supabase_client(self):
    """Test getting Supabase client"""
    
def test_save_decision_to_database(self):
    """Test saving decision to database"""
    
def test_get_user_decisions(self):
    """Test retrieving user decisions"""
```

**Coverage**: 39% of database layer code

#### Class: `TestRedisClient`
**Purpose**: Testing Redis cache operations

**Tested Functionalities**:
- âœ… Redis connection management
- âœ… Cache operations (set, get, delete)
- âœ… Error handling

#### Class: `TestDataValidation`
**Purpose**: Testing Pydantic model validation

**Tested Functionalities**:
- âœ… Network traffic features validation
- âœ… Decision response validation
- âœ… Invalid data handling

### 4. ML Preprocessor Tests (`test_preprocessor.py`)

#### Class: `TestDataPreprocessor`
**Purpose**: Testing ML data preprocessing component

**Tested Functionalities**:
- âœ… Preprocessor initialization
- âœ… Data fitting and transformation
- âœ… Numerical feature scaling (StandardScaler)
- âœ… Categorical feature encoding (OneHotEncoder)
- âœ… Missing value handling
- âœ… Different data type handling
- âœ… Edge cases (empty data, single rows)
- âœ… Transformation result consistency

**Key Tests**:
```python
def test_preprocessor_initialization(self):
    """Test preprocessor initialization"""
    
def test_fit_preprocessor(self):
    """Test fitting preprocessor on training data"""
    
def test_transform_data(self):
    """Test transforming new data"""
    
def test_numerical_features_scaling(self):
    """Test numerical feature scaling"""
    
def test_categorical_features_encoding(self):
    """Test categorical feature encoding"""
```

**Coverage**: 92% of ML preprocessor code

#### Class: `TestPreprocessorIntegration`
**Purpose**: Integration tests with realistic data

**Tested Functionalities**:
- âœ… Processing real network traffic data
- âœ… Transformation quality validation

### 5. UI Component Tests (`test_ui_components.py`)

#### Class: `TestUnifiedAppUI`
**Purpose**: Testing Gradio UI components

**Tested Functionalities**:
- âœ… Application initialization
- âœ… Email validation in UI
- âœ… Login handling (success/failure scenarios)
- âœ… Registration handling
- âœ… Logout functionality

**Key Tests**:
```python
def test_app_initialization(self):
    """Test UnifiedApp initialization"""
    
def test_validate_email_valid(self):
    """Test email validation with valid emails"""
    
def test_handle_login_success(self):
    """Test successful login handling"""
    
def test_handle_register_success(self):
    """Test successful registration handling"""
```

**Coverage**: 38% of UI components code

## ğŸ“Š Test Metrics

### Coverage Statistics
- **Overall code coverage**: 50%
- **API Layer**: 34% (needs improvement)
- **Authentication**: 71% (good)
- **Database**: 39% (needs improvement)
- **ML Preprocessor**: 92% (excellent)
- **UI Components**: 38% (needs improvement)

### Test Statistics
- **Total tests**: 53
- **Passing tests**: 53 (100%)
- **Failing tests**: 0 (0%)
- **Execution time**: ~6-7 seconds

### Detailed Results
```
tests/unit/test_api.py ...........                      [ 20%] 11/11 âœ…
tests/unit/test_auth.py ........                        [ 35%] 8/8 âœ…
tests/unit/test_database.py .........                   [ 52%] 9/9 âœ…
tests/unit/test_preprocessor.py .............           [ 77%] 13/13 âœ…
tests/unit/test_ui_components.py ............           [100%] 12/12 âœ…
```

## ğŸ”§ Configuration and Fixtures

### pytest.ini
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=80
markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    slow: Slow running tests
    security: Security-related tests
    ml: Machine learning tests
    api: API tests
    ui: UI tests
```

### conftest.py - Shared Fixtures
```python
@pytest.fixture
def temp_file():
    """Temporary file for file operation tests"""

@pytest.fixture
def mock_redis_client():
    """Mock Redis client for cache tests"""

@pytest.fixture
def mock_supabase_client():
    """Mock Supabase client for database tests"""
```

## ğŸ·ï¸ Test Categorization

### pytest Markers
- `@pytest.mark.unit` - Unit tests
- `@pytest.mark.security` - Security tests (authentication)
- `@pytest.mark.ml` - Machine learning tests (preprocessor)
- `@pytest.mark.ui` - User interface tests
- `@pytest.mark.api` - API tests
- `@pytest.mark.database` - Database tests

### Automatic Marking
Tests are automatically marked based on:
- File location (`unit/` â†’ `@pytest.mark.unit`)
- Test name (contains "auth" â†’ `@pytest.mark.security`)

## ğŸš€ Running Tests

### Basic Commands
```bash
# All unit tests
pytest tests/unit/

# Tests with code coverage
pytest tests/unit/ --cov=src --cov-report=term-missing

# Tests with HTML report
pytest tests/unit/ --cov-report=html

# Specific test file
pytest tests/unit/test_auth.py -v

# Tests with markers
pytest -m security
pytest -m ml
pytest -m api
```

### Test Filtering
```bash
# Tests containing "auth" in name
pytest -k "auth"

# Tests excluding slow ones
pytest -m "not slow"

# Specific test class
pytest -k "TestUnifiedApp"
```

## ğŸ“ˆ Reports and Analysis

### Generating Reports
```bash
# HTML report (open htmlcov/index.html)
pytest --cov-report=html

# XML report (for CI/CD)
pytest --cov-report=xml

# Terminal report with missing lines
pytest --cov-report=term-missing
```

### Coverage Analysis
- **HTML report**: Detailed line-by-line coverage analysis
- **XML report**: CI/CD system integration
- **Terminal report**: Quick console overview

## ğŸ” Detailed Test Analysis

### API Tests - Details

#### Health Check Endpoint
```python
def test_health_check(self):
    """Test health check endpoint"""
    response = self.client.get("/health")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert "model_loaded" in data
    assert "preprocessor_loaded" in data
```

**Tested aspects**:
- HTTP status code validation
- Response structure validation
- Service health indicators

#### Authentication Endpoints
```python
@patch('src.api.routes.auth.get_supabase_client')
def test_register_user_success(self, mock_supabase):
    """Test successful user registration"""
    # Arrange
    mock_client = Mock()
    mock_supabase.return_value = mock_client
    mock_client.sign_up.return_value = {
        "user": {"id": "new-user-id", "email": "test@example.com"},
        "session": {"access_token": "test-token"}
    }
    
    # Act
    user_data = {
        "email": "test@example.com",
        "password": "password123",
        "confirm_password": "password123"
    }
    response = self.client.post("/auth/register", json=user_data)
    
    # Assert
    assert response.status_code == 201
    data = response.json()
    assert data["email"] == "test@example.com"
    assert "access_token" in data
```

**Tested aspects**:
- HTTP request/response handling
- Mocking external dependencies
- Response structure validation
- Error handling

### Authentication Tests - Details

#### Email Validation
```python
def test_validate_email_valid(self):
    """Test validation of valid email addresses"""
    assert self.app.validate_email("test@example.com") == True
    assert self.app.validate_email("user.name@domain.co.uk") == True
```

**Tested cases**:
- Standard email addresses
- Email addresses with dots in username
- Email addresses with tags (+)

#### Login with Mocks
```python
@patch('requests.post')
def test_handle_login_success(self, mock_post):
    """Test successful login"""
    # Arrange
    mock_response = Mock()
    mock_response.status_code = 200
    mock_response.json.return_value = {
        "access_token": "test_token",
        "user_id": "test_user",
        "email": "test@example.com"
    }
    mock_post.return_value = mock_response
    
    # Act
    error_msg, status_msg, auth_data, tab_update = self.app.handle_login(
        "test@example.com", "password123"
    )
    
    # Assert
    assert error_msg == ""
    assert "Zalogowano pomyÅ›lnie" in status_msg
    assert auth_data["is_authenticated"] == True
```

**Tested aspects**:
- HTTP response mocking
- Response structure validation
- JWT token handling
- UI state updates

### Database Tests - Details

#### Supabase Client Operations
```python
@patch('src.core.supabaseclient.create_client')
def test_get_supabase_client(self, mock_create_client):
    """Test getting Supabase client"""
    mock_create_client.return_value = self.mock_client
    client = get_supabase_client()
    
    assert hasattr(client, 'client')
    assert hasattr(client, 'service_client')
```

**Tested aspects**:
- Client initialization
- Attribute validation
- Singleton pattern

#### Database Operations
```python
@patch('src.core.supabaseclient.get_supabase_client')
def test_save_decision_to_database(self, mock_get_client):
    """Test saving decision to database"""
    mock_get_client.return_value = self.mock_client
    self.mock_client.table.return_value.insert.return_value.execute.return_value = {
        "data": [{"id": 1, "user_id": "test-user", "classification_result": "NORMAL"}]
    }
    
    decision_data = {
        "user_id": "test-user",
        "classification_result": "NORMAL",
        "confidence_score": 0.85,
        "features": {"logged_in": True, "count": 45},
        "created_at": datetime.utcnow().isoformat()
    }
    
    result = self.mock_client.table("decisions").insert(decision_data).execute()
    assert result["data"][0]["classification_result"] == "NORMAL"
```

**Tested aspects**:
- Database insert operations
- Data structure validation
- Error handling

### ML Preprocessor Tests - Details

#### Initialization and Configuration
```python
def test_preprocessor_initialization(self):
    """Test preprocessor initialization"""
    assert self.preprocessor is not None
    assert hasattr(self.preprocessor, 'preprocessor')
    assert hasattr(self.preprocessor, 'selected_features')
    assert hasattr(self.preprocessor, 'categorical_features')
    assert hasattr(self.preprocessor, 'numerical_features')
```

**Tested aspects**:
- Object initialization
- Required attributes presence
- Numerical and categorical feature configuration

#### Fitting and Transformation
```python
def test_fit_preprocessor(self):
    """Test preprocessor fitting"""
    self.preprocessor.fit(self.sample_data)
    
    assert self.preprocessor.preprocessor is not None
    assert hasattr(self.preprocessor.preprocessor, 'transform')
```

**Tested aspects**:
- Training data fitting
- Transformer initialization
- Transform method availability

#### Feature Scaling
```python
def test_numerical_features_scaling(self):
    """Test numerical feature scaling"""
    self.preprocessor.fit(self.sample_data)
    transformed = self.preprocessor.transform(self.sample_data)
    
    # StandardScaler should center around 0
    assert np.abs(transformed.mean()) < 2.0
    assert transformed.std() > 0
```

**Tested aspects**:
- StandardScaler scaling
- Transformation statistics validation
- Different value range handling

## ğŸš¨ Error Handling and Edge Cases

### Negative Tests
```python
def test_handle_login_empty_inputs(self):
    """Test handling of empty input data"""
    error_msg, status_msg, auth_data, tab_update = self.app.handle_login("", "")
    
    assert "Email i hasÅ‚o sÄ… wymagane" in error_msg
    assert auth_data is None
```

### Edge Cases
```python
def test_empty_dataframe(self):
    """Test handling of empty DataFrame"""
    empty_df = pd.DataFrame(columns=self.preprocessor.selected_features)
    
    with pytest.raises(Exception):
        self.preprocessor.fit(empty_df)
```

### Exception Handling
```python
@patch('requests.post')
def test_handle_login_api_error(self, mock_post):
    """Test API error handling"""
    mock_post.side_effect = Exception("Connection failed")
    
    error_msg, status_msg, auth_data, tab_update = self.app.handle_login(
        "test@example.com", "password123"
    )
    
    assert "BÅ‚Ä…d podczas logowania" in error_msg
    assert auth_data is None
```

## ğŸ”„ CI/CD Integration

### GitHub Actions
```yaml
- name: Run unit tests
  run: |
    source venv/bin/activate
    pytest tests/unit/ --cov-report=xml --cov-fail-under=80
```

### Local CI Execution
```bash
# Run tests like in CI
pytest tests/unit/ --cov-report=xml --cov-fail-under=80 --tb=short
```

## ğŸ“‹ Quality Checklist

### âœ… Implemented
- [x] Unit test structure
- [x] API endpoint tests (11 tests)
- [x] Authentication tests (8 tests)
- [x] Database operation tests (9 tests)
- [x] ML preprocessor tests (13 tests)
- [x] UI component tests (12 tests)
- [x] Pytest configuration with code coverage
- [x] Shared fixtures and mocks
- [x] Test categorization with markers
- [x] HTML/XML reports
- [x] Edge case handling
- [x] Negative tests
- [x] Error handling tests

### ğŸ”„ To Be Implemented
- [ ] Integration tests
- [ ] End-to-end tests
- [ ] Performance tests
- [ ] Security tests
- [ ] Load testing

## ğŸ¯ Quality Metrics

### Requirements
- **Code coverage**: Minimum 80%
- **Execution time**: < 30 seconds
- **Test passing**: 100%
- **Regression tests**: Automatic execution

### Current Results
- **Code coverage**: 50% (overall), 92% (preprocessor), 71% (auth), 39% (database), 34% (API), 38% (UI)
- **Execution time**: ~6-7 seconds âœ…
- **Test passing**: 100% âœ…
- **Number of tests**: 53 âœ…

## ğŸ¤ Collaboration and Development

### Naming Conventions
- Test files: `test_*.py`
- Test classes: `Test*`
- Test methods: `test_*`
- Fixtures: descriptive names

### Adding New Tests
1. Create file in appropriate directory
2. Use existing fixtures
3. Add appropriate markers
4. Run tests locally
5. Check code coverage

### Test Documentation
Each test should contain:
- Docstring describing purpose
- Comments explaining business logic
- Clear variable names and assertions

## ğŸ“š Summary

The unit testing suite for the Intrusion Detector application provides:

1. **High code quality** - 100% test passing rate
2. **Good coverage** - 92% for preprocessor, 71% for authentication
3. **Fast execution** - ~6-7 seconds
4. **Easy extensibility** - Good structure and configuration
5. **CI/CD integration** - XML and HTML reports

The tests provide a solid foundation for further application development and ensure stability during changes.

## ğŸ”„ Recent Updates

### Removed Components
- **DocumentProcessor**: Removed unused document processing component
- **ClassificationAgent**: Removed unused classification agent component
- **LLMDecisionMaker**: Removed unused LLM decision maker component
- **SecurityPipeline**: Removed unused security pipeline orchestrator
- **Demo Pipeline**: Removed unused demo script

### Improved Test Coverage
- **API Tests**: Added comprehensive endpoint testing
- **Database Tests**: Added Supabase and Redis client testing
- **UI Tests**: Enhanced UI component testing
- **Overall Coverage**: Improved from 46% to 50%

### Test Stability
- **Pass Rate**: Improved from 72% to 100%
- **Test Count**: Optimized from 68 to 53 tests
- **Execution Time**: Reduced to ~6-7 seconds
